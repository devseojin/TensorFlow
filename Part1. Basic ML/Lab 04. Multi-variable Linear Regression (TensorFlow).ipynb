{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFYAAAAQCAYAAACMV4iGAAACxElEQVRYCd3XjY3UQAwF4CmBEiiBEugAOuBKoAPoADqADqCEK4EOoAPoAPSt8k4+a5Isu+F0nKUoMx7/PtuT3TGOoWdjjJsrTL0eY7y4Qv/RqwLnXXleLhF7V/7zkglQP5d9lsCqOrFVfYRH5/0DgSv2GtfbJeDOx+488WqAqh8s2Ak/GNx7344xfk+S/LjwKxgUAdJ5McgZW2Qq/RhjJKHwFehrNv/4DZxfY4xvzY848cQS0iByqBOZvHre8lqdPIaB20nSFCsJYCZbZSRQARNgBzryiteDzdnRb1MGsIAIELlkH3/2HVgx4tVYde5sck92YqR3k0MAdUUgAWOL0ukck+82qq7u2DqvsteuAQkcucp7Bmp8kKvNYI0n3pC4cy2Ed/eWOIXezqlQNUSJsc67M7YsOGPzU+vcLmcvwT4VM7mjeKbz+wJqz7n6IJcGEmOaJWBvditDgNKZFOrDMHAYraTKdRzqWV2Tm+lXmazJrVHskFl7yJxLaSTvLWIzduGSZgmwgO7Y3LOnW2ajCFhPJ872gOUwhdnrbvbPLUCP5ZI9QGZXXLdFTq7pVuf2Gf8A3PVO+9w5vXqMSXamfA6wPlxsK1r9iE2DeEBg5el+zVhvdZzcg0HuUbl7drs1PyGimMQzLrPO3ANWRaOX4Lr9+MlbAmvEn/Oth8weiSmTmbGefbBjJxgAMWT9c6XhInN666bZuAvAuMzI2dp4c1yDTQKzzo9tXbP18dL5QNl6tj5C/DjvkyNvH7E14k8xa1PIAy5bnX76GUSR8QRG4c1SFZV5NfGqkrWKROh9WAKJDp41H7E1C0iR0kkTd1ezxMu/XygBSb5fltj8cwq/OsPrcWmarSap+n+9Bs45o3euYcHrjsdIvRHsO+/QuFXtCDAE2Uf00ED/N2MA6WNySQ4KlGvoEv0nqQNc99el5G59UqD+AYAjv71SVNlkAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-variable linear regression\n",
    "    - 다변량 선형 회귀함수\n",
    "\n",
    "* Matrix multiplication 이용 (dot product: 내적)\n",
    "\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "     - 이론과 표현방법에서 차이가 있음 (내적 계산법 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example : 2 variables with Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]\n",
      "\n",
      "    0 |      1.871500 |        0.5008 |        0.7113 |      0.109362\n",
      "   50 |      0.444546 |        0.7327 |        0.7912 |      0.190253\n",
      "  100 |      0.117729 |        0.8401 |        0.8392 |      0.228519\n",
      "  150 |      0.040049 |        0.8899 |        0.8687 |      0.245941\n",
      "  200 |      0.020316 |        0.9130 |        0.8873 |      0.253042\n",
      "  250 |      0.014689 |        0.9239 |        0.8993 |      0.254958\n",
      "  300 |      0.012747 |        0.9293 |        0.9073 |      0.254228\n",
      "  350 |      0.011867 |        0.9321 |        0.9129 |      0.252129\n",
      "  400 |      0.011331 |        0.9339 |        0.9168 |      0.249316\n",
      "  450 |      0.010921 |        0.9351 |        0.9198 |      0.246131\n",
      "  500 |      0.010565 |        0.9362 |        0.9220 |      0.242758\n",
      "  550 |      0.010236 |        0.9371 |        0.9239 |      0.239298\n",
      "  600 |      0.009924 |        0.9381 |        0.9255 |      0.235808\n",
      "  650 |      0.009624 |        0.9390 |        0.9269 |      0.232321\n",
      "  700 |      0.009334 |        0.9399 |        0.9282 |      0.228856\n",
      "  750 |      0.009053 |        0.9408 |        0.9294 |      0.225424\n",
      "  800 |      0.008781 |        0.9416 |        0.9306 |      0.222033\n",
      "  850 |      0.008517 |        0.9425 |        0.9317 |      0.218684\n",
      "  900 |      0.008261 |        0.9434 |        0.9328 |      0.215382\n",
      "  950 |      0.008013 |        0.9442 |        0.9338 |      0.212126\n",
      " 1000 |      0.007772 |        0.9451 |        0.9348 |      0.208918\n"
     ]
    }
   ],
   "source": [
    "x_data = [\n",
    "    [1., 0., 3., 0., 5.],\n",
    "    [0., 2., 0., 4., 0.]\n",
    "]\n",
    "y_data  = [1, 2, 3, 4, 5]\n",
    "\n",
    "W = tf.Variable(tf.random.uniform((1, 2), -1.0, 1.0))\n",
    "b = tf.Variable(tf.random.uniform((1,), -1.0, 1.0))\n",
    "\n",
    "learning_rate = tf.Variable(0.001)\n",
    "\n",
    "print(\"     i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]\\n\")\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.matmul(W, x_data) + b       # (1, 2) * (2, 5) = (1, 5)\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "        W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "        W.assign_sub(learning_rate * W_grad)\n",
    "        b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:13.6f} | {:13.4f} | {:13.4f} | {:13.6f}\".format(\n",
    "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypothesis without b\n",
    "- b 삭제하는 대신 변수 2개이지만 열(column) 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]\n",
      "\n",
      "    0 |      8.116693 |       -0.7343 |        0.2426 |        0.6033\n",
      "   50 |      1.963493 |       -0.5459 |        0.7065 |        0.7966\n",
      "  100 |      0.516823 |       -0.4479 |        0.9183 |        0.9124\n",
      "  150 |      0.158433 |       -0.3948 |        1.0138 |        0.9828\n",
      "  200 |      0.062294 |       -0.3644 |        1.0558 |        1.0260\n",
      "  250 |      0.033582 |       -0.3456 |        1.0736 |        1.0525\n",
      "  300 |      0.023830 |       -0.3330 |        1.0804 |        1.0687\n",
      "  350 |      0.019996 |       -0.3237 |        1.0823 |        1.0785\n",
      "  400 |      0.018208 |       -0.3163 |        1.0822 |        1.0843\n",
      "  450 |      0.017188 |       -0.3101 |        1.0813 |        1.0875\n",
      "  500 |      0.016479 |       -0.3045 |        1.0801 |        1.0890\n",
      "  550 |      0.015905 |       -0.2993 |        1.0788 |        1.0895\n",
      "  600 |      0.015393 |       -0.2944 |        1.0775 |        1.0893\n",
      "  650 |      0.014917 |       -0.2898 |        1.0763 |        1.0888\n",
      "  700 |      0.014463 |       -0.2852 |        1.0751 |        1.0879\n",
      "  750 |      0.014026 |       -0.2808 |        1.0739 |        1.0869\n",
      "  800 |      0.013603 |       -0.2765 |        1.0727 |        1.0858\n",
      "  850 |      0.013194 |       -0.2723 |        1.0716 |        1.0846\n",
      "  900 |      0.012797 |       -0.2681 |        1.0705 |        1.0834\n",
      "  950 |      0.012412 |       -0.2641 |        1.0694 |        1.0822\n",
      " 1000 |      0.012039 |       -0.2601 |        1.0684 |        1.0810\n"
     ]
    }
   ],
   "source": [
    "x_data = [\n",
    "    [1., 1., 1., 1., 1.], # bias(b)\n",
    "    [1., 0., 3., 0., 5.], \n",
    "    [0., 2., 0., 4., 0.]\n",
    "]\n",
    "y_data  = [1, 2, 3, 4, 5]\n",
    "\n",
    "W = tf.Variable(tf.random.uniform((1, 3), -1.0, 1.0)) # [1, 3]으로 변경하고, b 삭제\n",
    "\n",
    "learning_rate = 0.001\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate)\n",
    "\n",
    "print(\"     i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], b.numpy()[0]\\n\")\n",
    "for i in range(1000+1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = tf.matmul(W, x_data) # b가 없다\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - y_data))\n",
    "\n",
    "    grads = tape.gradient(cost, [W])\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads,[W]))\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:13.6f} | {:13.4f} | {:13.4f} | {:13.4f}\".format(\n",
    "            i, cost.numpy(), W.numpy()[0][0], W.numpy()[0][1], W.numpy()[0][2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Gradient\n",
    "* tf.train.GradientDescentOptimizer(): optimizer\n",
    "* optimizer.apply_gradients(): update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    0 |   3.360607\n",
      "   50 |   0.018925\n",
      "  100 |   0.012939\n",
      "  150 |   0.008847\n",
      "  200 |   0.006049\n",
      "  250 |   0.004135\n",
      "  300 |   0.002827\n",
      "  350 |   0.001933\n",
      "  400 |   0.001322\n",
      "  450 |   0.000904\n",
      "  500 |   0.000618\n",
      "  550 |   0.000422\n",
      "  600 |   0.000289\n",
      "  650 |   0.000197\n",
      "  700 |   0.000135\n",
      "  750 |   0.000092\n",
      "  800 |   0.000063\n",
      "  850 |   0.000043\n",
      "  900 |   0.000030\n",
      "  950 |   0.000020\n",
      " 1000 |   0.000014\n"
     ]
    }
   ],
   "source": [
    "# Multi-variable linear regression (1)\n",
    "\n",
    "X = tf.constant([[1., 2.], \n",
    "                 [3., 4.]])\n",
    "y = tf.constant([[1.5], [3.5]])\n",
    "\n",
    "W = tf.Variable(tf.random.normal((2, 1)))      # 임의의 값 또는 random으로 부여\n",
    "b = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "# Create an optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "n_epoch = 1000+1\n",
    "print(\"epoch | cost\")\n",
    "for i in range(n_epoch):\n",
    "    \n",
    "    # Use tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = tf.matmul(X, W) + b\n",
    "        cost = tf.reduce_mean(tf.square(y_pred - y))\n",
    "\n",
    "    # calculates the gradients of the loss\n",
    "    grads = tape.gradient(cost, [W, b])\n",
    "    \n",
    "    # updates parameters (W and b)\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\n",
    "    if i % 50 == 0:\n",
    "        print(\"{:5} | {:10.6f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 예제) Predicting exam score\n",
    "    - regression using three inputs (x1, x2, x3)\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 변수\n",
    "x1 = [ 73.,  93.,  89.,  96.,  73.]\n",
    "\n",
    "x2 = [ 80.,  88.,  91.,  98.,  66.]\n",
    "\n",
    "x3 = [ 75.,  93.,  90., 100.,  70.]\n",
    "\n",
    "Y  = [152., 185., 180., 196., 142.]\n",
    "\n",
    "##### weights\n",
    "w1 = tf.Variable(10.)\n",
    "\n",
    "w2 = tf.Variable(10.)\n",
    "\n",
    "w3 = tf.Variable(10.)\n",
    "\n",
    "b  = tf.Variable(10.)\n",
    "\n",
    "##### 가설\n",
    "hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    i,      cost\n",
      "\n",
      "    0 | 5793889.5000\n",
      "   50 |   64291.1484\n",
      "  100 |     715.2902\n",
      "  150 |       9.8462\n",
      "  200 |       2.0152\n",
      "  250 |       1.9252\n",
      "  300 |       1.9210\n",
      "  350 |       1.9177\n",
      "  400 |       1.9145\n",
      "  450 |       1.9114\n",
      "  500 |       1.9081\n",
      "  550 |       1.9050\n",
      "  600 |       1.9018\n",
      "  650 |       1.8986\n",
      "  700 |       1.8955\n",
      "  750 |       1.8923\n",
      "  800 |       1.8892\n",
      "  850 |       1.8861\n",
      "  900 |       1.8829\n",
      "  950 |       1.8798\n",
      " 1000 |       1.8767\n"
     ]
    }
   ],
   "source": [
    "# Matrix 사용하지 않고, 각각 w를 부여함 (업데이트 할 때도 각각 정의해야함)\n",
    "\n",
    "# data and label\n",
    "x1 = [ 73.,  93.,  89.,  96.,  73.]\n",
    "x2 = [ 80.,  88.,  91.,  98.,  66.]\n",
    "x3 = [ 75.,  93.,  90., 100.,  70.]\n",
    "Y  = [152., 185., 180., 196., 142.]\n",
    "\n",
    "# weights\n",
    "w1 = tf.Variable(10.)           # w1 = tf.Variable(tf.random.normal((1,))) 와 동일\n",
    "w2 = tf.Variable(10.)\n",
    "w3 = tf.Variable(10.)\n",
    "b  = tf.Variable(10.)\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "print(\"    i,      cost\\n\")\n",
    "for i in range(1000+1):\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        hypothesis = w1 * x1 +  w2 * x2 + w3 * x3 + b\n",
    "        cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "    # calculates the gradients of the cost\n",
    "    w1_grad, w2_grad, w3_grad, b_grad = tape.gradient(cost, [w1, w2, w3, b])\n",
    "    \n",
    "    # update w1,w2,w3 and b\n",
    "    w1.assign_sub(learning_rate * w1_grad)\n",
    "    w2.assign_sub(learning_rate * w2_grad)\n",
    "    w3.assign_sub(learning_rate * w3_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "\n",
    "    if i % 50 == 0:\n",
    "      print(\"{:5} | {:12.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-variable linear regression : Matrix 사용\n",
    "    - numpy 사용하여 matrix로 변수 x와 label y를 묶어줌\n",
    "    - W = tf.Variable 에서도 행렬 (3, 1)로 선언\n",
    "    - 가설 함수의 return값에 matmul 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch | cost\n",
      "    0 |  1798.2894\n",
      "  100 |     2.2888\n",
      "  200 |     2.0632\n",
      "  300 |     2.0587\n",
      "  400 |     2.0542\n",
      "  500 |     2.0498\n",
      "  600 |     2.0453\n",
      "  700 |     2.0409\n",
      "  800 |     2.0366\n",
      "  900 |     2.0322\n",
      " 1000 |     2.0279\n",
      " 1100 |     2.0236\n",
      " 1200 |     2.0194\n",
      " 1300 |     2.0151\n",
      " 1400 |     2.0108\n",
      " 1500 |     2.0066\n",
      " 1600 |     2.0024\n",
      " 1700 |     1.9982\n",
      " 1800 |     1.9940\n",
      " 1900 |     1.9899\n",
      " 2000 |     1.9857\n"
     ]
    }
   ],
   "source": [
    "data = np.array([\n",
    "    # X1,   X2,    X3,   y\n",
    "    [ 73.,  80.,  75., 152. ],\n",
    "    [ 93.,  88.,  93., 185. ],\n",
    "    [ 89.,  91.,  90., 180. ],\n",
    "    [ 96.,  98., 100., 196. ],\n",
    "    [ 73.,  66.,  70., 142. ]\n",
    "], dtype=np.float32)\n",
    "\n",
    "# slice data\n",
    "X = data[:, :-1]\n",
    "y = data[:, [-1]]\n",
    "\n",
    "W = tf.Variable(tf.random.normal((3, 1)))\n",
    "b = tf.Variable(tf.random.normal((1,)))\n",
    "\n",
    "learning_rate = 0.000001\n",
    "\n",
    "# hypothesis, prediction function\n",
    "def predict(X):\n",
    "    return tf.matmul(X, W) + b\n",
    "\n",
    "print(\"epoch | cost\")\n",
    "\n",
    "n_epochs = 2000\n",
    "for i in range(n_epochs+1):\n",
    "    # tf.GradientTape() to record the gradient of the cost function\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost = tf.reduce_mean((tf.square(predict(X) - y)))\n",
    "\n",
    "    # calculates the gradients of the loss\n",
    "    W_grad, b_grad = tape.gradient(cost, [W, b])\n",
    "\n",
    "    # updates parameters (W and b)\n",
    "    W.assign_sub(learning_rate * W_grad)\n",
    "    b.assign_sub(learning_rate * b_grad)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"{:5} | {:10.4f}\".format(i, cost.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6652976 ],\n",
       "       [ 0.59528816],\n",
       "       [-0.25148827]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight 값 확인\n",
    "W.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.0683131], dtype=float32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[151.39648],\n",
       "       [184.93794],\n",
       "       [180.81708],\n",
       "       [194.1263 ],\n",
       "       [144.31987]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 가설함수 결과 = 실제 값 예측\n",
    "tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[152.0, 185.0, 180.0, 196.0, 142.0]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels, 실제값\n",
    "Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151.39648],\n",
       "       [184.93794],\n",
       "       [180.81708],\n",
       "       [194.1263 ],\n",
       "       [144.31987]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(X).numpy() # prediction, 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[182.69525],\n",
       "       [174.3433 ]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 새로운 데이터에 대한 예측\n",
    "\n",
    "predict([[ 89.,  95.,  92.],[ 84.,  92.,  85.]]).numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
